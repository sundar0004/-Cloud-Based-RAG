# Viva Preparation Pack

## 1. 3-Minute Pitch
This project addresses LLM hallucination by integrating retrieval with generation in a cloud-ready architecture. I implemented baseline and RAG variants, measured factuality, hallucination proxy, retrieval quality, and latency, then analyzed tradeoffs. Results show retrieval-grounded generation improves factual behavior while introducing manageable latency overhead.

## 2. Expected Viva Questions
1. Why this topic?
2. Why RAG instead of only prompt engineering?
3. How did you define hallucination?
4. Why these metrics?
5. What are threats to validity?
6. How reproducible is your setup?
7. What would you improve with more time?

## 3. Strong Answer Strategy
- Always connect claims to measured evidence.
- State limitations directly.
- Show one failure case and what caused it.
- Explain why design choices are practical for enterprise use.

## 4. Demo Flow (5-7 minutes)
1. Show architecture diagram.
2. Run baseline query.
3. Run RAG query on same question.
4. Show retrieved evidence and output difference.
5. Present summary metrics chart.

## 5. Slide Deck Outline
1. Problem and motivation
2. Research questions and objectives
3. Architecture and implementation
4. Experimental setup
5. Results and insights
6. Limitations and future work
7. Conclusion
